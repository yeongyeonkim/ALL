kubelet 안에 cadvisor(도커 모니터링 툴) 포함되어 있어
c-advisor는 각각 워커노드에서 리소스 정보를 수집해서 mater노드에 api로 보내
api는 이벤트가 발생할 때마다 수집해서 etcd에 key value(nosql)방식으로 보존함

컴퓨터에서 실행 요청하면 마스터에 요청이 가서 api가 인증함
인증
1. api 문법에 맞는지 확인, 권한이 있는지 확인
2. etcd 에서 리소스 정보를 가져옴
3. 가져온 정보를 scheduler에게 줌
4. scheduler가 받아온 정보로 실행할 컨테이너를 리소스 정보에 점수를 매겨서 분산 스케줄링
5. api는 컨트롤러에게 실행될것을 알려줌 컨트롤는 갯수보장하기 위해 왓치
6. 요청을 받은 kublet은 도커에게 전달
7. 도커는 run 함
8. 도커는 실행하면서 컨테이너 ip가 생성됨
9. 실수로 노드 하나를 꺼버리면 컨트롤러가 감시하고 있다가 api에게 이야기함
10. api는 스케줄러에 이야기 스케줄러는 다른노드에 요청

노드는 ip가 분리되어 있어서 특정 노드에만 붙을 수 있기때문에 로드밸런스가 필요해
로드밸런스는 service로 처리됨
service : cluterip(vip)
클러스터 ip는 랜덤하게 지정됨. 여기에 붙을 필요는 없으니까
랜덤하지만 라운드로빈은 아니야 
서비스가 만들어지만 api는 큐블렛에 iptable을 만들라고 일을 시켜
큐블렛은 iptable을 만들수 있는 권한이 없어 대신 bude-proxt가 컨터이너로 동작 중인데 얘가 루트권한을 갖고 있어
큐블렛은 큐브프록시에 토스해서 큐브프록시가 iptable을 만들어
그리고 큐브프록시가 포트리슨하고 있어 
아무 노드로 요청이들어오면 ip테이블을 보고 엔드포인트 정보로 연결시킴(iptable은 모든 노드가 같아)

컨터이너는 리눅스에서 실행해야하는 이유 리눅스커널에서 isolation해주는 기능이 있어서
클러스터ip는 컨네이너간 통신에 유용히 사용됨
etcd에 클러스터ip가 변경되는 경우때문에 coredns가 존재
모든 컨테이너 maindns가 coredns
ip가 변경되면 coredns가 변경됨