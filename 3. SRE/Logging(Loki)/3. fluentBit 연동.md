## 목표

먼저, Postman을 사용해서 우리의 컨테이너 로그 형태를 확인한다.

- 2025-08-27 13:43:06,001INFO [domain:test][LogAspect][123456][http-nio-1234-exec-7] [RESPONSE][getTestIdByUserId]->DATA[<200 OK OK,GetTestIdDTO(testId=2025kimyeongyeon),[resultCode:"1234", resultMessage:"%A0%B1%C2%D3"]>]->(123ms) -- [trace_id,span_id]

위처럼 우리는 resultCode라는 값을 추가적으로 주고있다.
HTTP Status Code 200이어도 내부 로직을 resultCode라는 값으로 한 번 더 거치게되고 이때 서비스 내부적으로는 실패로 response를 던지겠지만
APM 도구로 본 이 에러는 200이기 때문에 감지가되지 않는다.

이 상황이 누적해서 쌓이게되면 장애로 이어지게 된다.

따라서, 우리는 Logging을 통한 장애 인지가 필요하다



### Loki에 데이터 보내기

* 먼저 FluentBit -> Loki로 로그 데이터를 전송하고 원하는 값으로 필터링이 되는지 확인한다. (이후에 Opentelemetry 를 구성한다)

* [공식문서](https://docs.fluentbit.io/manual/data-pipeline/outputs/loki)를 참고하여 데이터 파이프라인을 구축한다.

### FluentBit DataPipeline

* https://docs.fluentbit.io/manual/concepts/data-pipeline

* FluentBit에는 데이터 파이프라인이 존재하고, Filters, Inputs, Outputs, Parses 등을 설정할 수 있다.

※ Pipeline workflows
 - Input -> Parser -> Filter -> Buffer

#### 쿠버네티스 기본 로그 레코드 구조

```
{
  "time": "2024-01-15T10:30:00.000Z",
  "log": "actual log message here",
  "stream": "stdout",
  "kubernetes": {
    "pod_name": "my-app-12345",
    "namespace_name": "production",
    "container_name": "app",
    "labels": {
      "app": "my-application",
      "version": "v1.2.3",
      "team": "backend"
    },
    "annotations": {
      "deployment.kubernetes.io/revision": "1"
    }
  }
}
```

* 이는, 이후에 labels를 정의할 때 namespace=$kubernetes['namespace_name'] 이런식으로 사용할 수 있다.
 
 
#### Inputs

* 기존 설정
```
    [INPUT]
        Name                tail
        Tag                 application.*
        Exclude_Path        /var/log/containers/cloudwatch-agent*, /var/log/containers/fluent-bit*, /var/log/containers/aws-node*, /var/log/containers/kube-proxy*
        Path                /var/log/containers/*.log
        multiline.parser    docker, cri
        DB                  /var/fluent-bit/state/flb_container.db
        Mem_Buf_Limit       50MB
        Skip_Long_Lines     On
        Refresh_Interval    10
        Rotate_Wait         30
        storage.type        filesystem
        Read_from_Head      Off  
```


#### Filters

* 기존 설정
```
    [FILTER]
        Name kubernetes
        Match kube.*
        Merge_Log On
        Keep_Log Off
        K8S-Logging.Parser On
        K8S-Logging.Exclude On
```

<b>Filter.rewrite_tag</b>
 - [문서](https://docs.fluentbit.io/manual/data-pipeline/filters/rewrite-tag)
 - 기존 로그는 영향을 주지 않기 위해 FILTER.rewrite_tag를 사용하여 레코드를 새로운 태그에 다시 보낼 수 있다.
 - FILTER Match에는 받아올 레코드의 INPUT Tag와 매칭시켜준다.
 - Rule은 단순히 모든 application 로그를 loki로 복제하는 명령(+ Keep을 false로 하여 원본 레코드 삭제)
```
    [FILTER]
        Name rewrite_tag
        Match application.*
        Rule $log ^(.*)$ loki.application false
        Emitter_Name loki_rewriter
```

```
    # Loki 자체 로그 제외
    [FILTER]
        Name    grep
        Match   loki.*
        Exclude log loki/api/v1/push
```

#### Outputs

```
    [OUTPUT]
        name                         loki
        match                        loki.*
        host                         loki-gateway.default.svc.cluster.local
        port                         80
        labels                       job=fluent-bit
        auto_kubernetes_labels       On
```
(초기설정)


#### FILTER 개선

* 로그가 너무 잡다한 것이 많이 들어와서, 로깅을 해야하는 서비스들의 컨테이너 로그만 가져올 수 있게 한다.

```
    [INPUT]
        Name                tail
        Tag                 slog
        Path                /var/log/containers/s-*.log
        multiline.parser    docker, cri
        DB                  /var/fluent-bit/state/flb_s_container.db
        Mem_Buf_Limit       50MB
        Skip_Long_Lines     On
        Refresh_Interval    10
        Rotate_Wait         30
        storage.type        filesystem
        Read_from_Head      Off
		
    [FILTER]
        Name rewrite_tag
        Match slog
        Rule $log ^(.*)$ loki.application false
        Emitter_Name loki_rewriter


```


### 참고 자료

* https://docs.fluentbit.io/manual/data-pipeline/outputs/loki