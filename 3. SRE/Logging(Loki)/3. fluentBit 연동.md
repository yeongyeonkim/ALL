## 목표

먼저, Postman을 사용해서 우리의 컨테이너 로그 형태를 확인한다.

- 2025-08-27 13:43:06,001INFO [domain:test][LogAspect][123456][http-nio-1234-exec-7] [RESPONSE][getTestIdByUserId]→DATA[<200 OK OK,GetTestIdDTO(testId=2025kimyeongyeon),[resultCode:"1234", resultMessage:"%A0%B1%C2%D3"]>]→(123ms) -- [trace_id,span_id]

위처럼 우리는 resultCode라는 값을 추가적으로 주고있다.
HTTP Status Code 200이어도 내부 로직을 resultCode라는 값으로 한 번 더 거치게되고 이때 서비스 내부적으로는 실패로 response를 던지겠지만
APM 도구로 본 이 에러는 200이기 때문에 감지가되지 않는다.

이 상황이 누적해서 쌓이게되면 장애로 이어지게 된다.

따라서, 우리는 Logging을 통한 장애 인지가 필요하다

### Logging 시스템

* 프로젝트 내부에서 기존에 S3 + GrayLog 기반의 아키텍처로 로그를 전달하기 위해 fluentbit을 사용하고 있었다
* Alloy와 같은 다른 시스템을 구성하는 것도 좋지만, 관리 포인트와 러닝 커브가 하나 더 생기는 것이기 때문에 특별히 우리의 목표를 구현하는데 있어서 어려움이없다면 fluentbit을 사용한다.

* 아키텍처는 다음과 같아진다.

기존 컨테이너 로그 → S3
특정 컨테이너 로그 → Loki 

### FluentBit DataPipeline

* https://docs.fluentbit.io/manual/concepts/data-pipeline

* FluentBit에는 데이터 파이프라인이 존재하고, Filters, Inputs, Outputs, Parses 등을 설정할 수 있다.

※ Pipeline workflows
 - Input → Parser → Filter → Buffer → Output
 
### Fluent Bit 주요 컴포넌트

#### Inputs
 
* 로그 데이터를 수집하는 소스를 설정하는 기능

```
    ## 대부분의 컨테이너 로그 S3로 전송하기 위한 INPUT
    [INPUT]
        Name                tail
        Tag                 application.*
        Exclude_Path        /var/log/containers/cloudwatch-agent*, /var/log/containers/fluent-bit*, /var/log/containers/aws-node*, /var/log/containers/kube-proxy*
        Path                /var/log/containers/*.log
        multiline.parser    docker, cri
        DB                  /var/fluent-bit/state/flb_container.db
        Mem_Buf_Limit       50MB
        Skip_Long_Lines     On
        Refresh_Interval    10
        Rotate_Wait         30
        storage.type        filesystem
        Read_from_Head      Off  
	
	## 대부분의 컨테이너 로그 S3로 전송하기 위한 INPUT
    [INPUT]
        Name                tail
        Tag                 testlog
        Path                /var/log/containers/test-*.log
        multiline.parser    docker, cri
        DB                  /var/fluent-bit/state/flb_test_container.db
        Mem_Buf_Limit       50MB
        Skip_Long_Lines     On
        Refresh_Interval    10
        Rotate_Wait         30
        storage.type        filesystem
        Read_from_Head      Off

```


#### Filters

* 로그 데이터를 조건에 따라 선별, 변환, 또는 제거하는 기능

```
    [FILTER]
        Name kubernetes
        Match kube.*
        Merge_Log On
        Keep_Log Off
        K8S-Logging.Parser On
        K8S-Logging.Exclude On
		
	## 새로운 TAG에 재전송
    [FILTER]
        Name rewrite_tag
        Match testlog
        Rule $log ^(.*)$ loki.application false
        Emitter_Name loki_rewriter
        
	## 로키 자체 로그 제외
    [FILTER]
        Name    grep
        Match   loki.*
        Exclude log loki/api/v1/push

    ## 루아 스크립트 적용
    [FILTER]
        Name    lua
        Match   loki.*
        script  /fluent-bit/etc/conf/extract_http_status.lua
        call    extract_http_status
```

<b>Filter.rewrite_tag</b>
 - [문서](https://docs.fluentbit.io/manual/data-pipeline/filters/rewrite-tag)
 - 기존 로그는 영향을 주지 않기 위해 FILTER.rewrite_tag를 사용하여 레코드를 새로운 태그에 다시 보낼 수 있다.
 - FILTER Match에는 받아올 레코드의 INPUT Tag와 매칭시켜준다.
 - Rule은 단순히 모든 application 로그를 loki로 복제하는 명령(+ Keep을 false로 하여 원본 레코드 삭제)


#### Outputs

* 처리된 로그 데이터를 전송할 목적지 설정하는 기능(S3, Loki)

```
    [OUTPUT]
        Name                         s3
        Match                        application.*
        bucket                       fluentbit-bucket
        region                       ap-northeast-2
        compression                  gzip
        use_put_object               On
        s3_key_format                /dt=%Y%m%d/hour=%H/fluentbit_%H%M_$UUID.gz
        s3_key_format_tag_delimiters .-
        total_file_size              10M
        upload_timeout               5m
        storage_class                INTELLIGENT_TIERING

    [OUTPUT]
        name                         loki
        match                        loki.*
        host                         loki-gateway.default.svc.cluster.local
        port                         80
        labels                       job=fluent-bit
        label_keys                   $stream,$http_status
```

#### extraFiles

* 외부 파일을 참조하여 추가적인 처리 로직을 적용하는 기능
* 로그 내에 특정 형식으로 존재하는 데이터를 Label을 통해 필터링하기 위해 정규식을 적용하여 추출하고, 이를 레코드화하여 OUTPUT의 label key로 설정합니다.
  - `DTODATA[>200` 이라는 데이터를 http_status로 레코드화

```
  extraFiles: 
    extract_http_status.lua: |
      function extract_http_status(tag, timestamp, record)
          local log = record["log"]
          if log ~= nil then
              local status = string.match(log, "DTODATA%[%&lt;(%d%d%d)")
              if status ~= nil then
                  record["http_status"] = status
              end
          end
          return 1, timestamp, record
      end
```

#### PARSER 

* `Time_Keep` 옵션은 로그의 타임스탬프 처리 방식인데, 로그 메시지 안의 time 값을 fluent-bit이 수집한 시간으로 덮어씌울지 말지를 정한다.
  정확한 시간 순서가 중요한 경우, On 설정한다.

### Grafana에서 LogQL 하기

$ {job="fluent-bit",stream="stdout",http_status!="200"} |= "domain:" |= "resultCode:" !~ "resultCode:\"(0000|000)\""

![extrafile](img/extraFiles, lua, http_status.png)

### 참고 자료

* https://docs.fluentbit.io/manual/data-pipeline/pipeline-monitoring